{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a6fadb3-baa6-4e5d-bbb2-db93c45a01eb",
   "metadata": {},
   "source": [
    "Q1. What is Random Forest Regressor?\n",
    "\r\n",
    "Random Forest Regressor is an ensemble learning algorithm that belongs to the family of decision tree-based methods. It is used for regression tasks, where the goal is to predict a continuous numeric output. The algorithm builds multiple decision trees during training and outputs the average prediction (for regression) based on the predictions of individual trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4160b6-76b7-4cfd-af28-1ed0afca7fa2",
   "metadata": {},
   "source": [
    "Q2. How does Random Forest Regressor reduce the risk of overfitting?\n",
    "\r\n",
    "Random Forest Regressor reduces the risk of overfitting through the following mechanisms:\r\n",
    "\r\n",
    "Bootstrap Sampling: The algorithm uses bootstrap sampling to create multiple subsets of the training data for each tree. This introduces diversity in the training sets, reducing the impact of outliers and noise.\r\n",
    "\r\n",
    "Feature Randomization: At each split in a decision tree, only a random subset of features is considered. This prevents individual trees from becoming too specialized and overfitting to specific features.\r\n",
    "\r\n",
    "Averaging Predictions: The final prediction is an average of predictions from all the individual trees. This ensemble averaging helps to smooth out noise and variance, resulting in a more robust and generalizable model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc7a8f8-62c9-406f-a222-fa56da178525",
   "metadata": {},
   "source": [
    "Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?\n",
    "\r\n",
    "Random Forest Regressor aggregates predictions through averaging. The algorithm follows these steps:\r\n",
    "\r\n",
    "Bootstrap Sampling:\r\n",
    "\r\n",
    "Randomly select subsets of the training data with replacement to create multiple bootstrap sam\n",
    "ples.\r\n",
    "Decision Tree Training:\r\n",
    "\r\n",
    "Build a decision tree for each bootstrap sample. However, at each split, only a random subset of features is con\n",
    "sidered.\r\n",
    "Prediction:\r\n",
    "\r\n",
    "For a new input, obtain predictions from all the indivi\n",
    "dual trees.\r\n",
    "Averaging:\r\n",
    "\r\n",
    "The final prediction is the average of the predictions from all the decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a3bd3d-1876-4c91-8391-a5cc9056f1d8",
   "metadata": {},
   "source": [
    "Q4. What are the hyperparameters of Random Forest Regressor?\n",
    "\r\n",
    "Some key hyperparameters of Random Forest Regressor include:\r\n",
    "\r\n",
    "n_estimators: Number of decision trees in the forest.\r\n",
    "max_depth: Maximum depth of each decision tree.\r\n",
    "min_samples_split: Minimum number of samples required to split an internal node.\r\n",
    "min_samples_leaf: Minimum number of samples required to be at a leaf node.\r\n",
    "max_features: The number of features to consider when looking for the best split.\r\n",
    "These hyperparameters control the complexity, size, and behavior of the Random Forest Regressor. Proper tuning of these parameters is essential for achieving optimal performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a5f018-dc61-443d-bc8f-cbf61bf0b00d",
   "metadata": {},
   "source": [
    "Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?\n",
    "\r\n",
    "Random Forest Regressor:\r\n",
    "\r\n",
    "Ensemble method that builds multiple decision trees.\r\n",
    "Uses bootstrap sampling and feature randomization.\r\n",
    "Averages predictions from multiple trees for the final output.\r\n",
    "Reduces overfitting and provides more robust predictions.\r\n",
    "Decision Tree Regressor:\r\n",
    "\r\n",
    "Single decision tree without ensemble.\r\n",
    "No bootstrap sampling or feature randomization.\r\n",
    "Prone to overfitting, especially in the presence of noise.\r\n",
    "Simpler and interpretable but lacks the robustness of Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f5bffd-d723-4cb0-978a-a86749e53711",
   "metadata": {},
   "source": [
    "Q6. What are the advantages and disadvantages of Random Forest Regressor?\n",
    "\r\n",
    "Advantages:\r\n",
    "\r\n",
    "Robustness: Resistant to overfitting and noise.\r\n",
    "Accuracy: Generally provides high predictive accuracy.\r\n",
    "Feature Importance: Can rank the importance of features.\r\n",
    "Disadvantages:\r\n",
    "\r\n",
    "Complexity: The model can become complex with a large number of trees.\r\n",
    "Computational Intensity: Training and predicting can be computationally expensive.\r\n",
    "Interpretability: Less interpretable compared to individual decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66caa77-e308-40f5-9653-47b9194372a3",
   "metadata": {},
   "source": [
    "Q7. What is the output of Random Forest Regressor?\n",
    "\r\n",
    "The output of a Random Forest Regressor is a continuous numeric value, representing the predicted outcome for a given input. For each input, the algorithm aggregates the predictions from all the decision trees in the ensemble and outputs the average prediction as the final result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e21765-74d0-4249-96b3-e9e5e750812f",
   "metadata": {},
   "source": [
    "Q8. Can Random Forest Regressor be used for classification tasks?\n",
    "\r\n",
    "Yes, Random Forest can be used for classification tasks as well. When applied to classification, it is referred to as Random Forest Classifier. The mechanism is similar, but instead of averaging predictions, it uses voting to determine the final class. Each tree in the ensemble \"votes\" for a class, and the class with the majority of votes becomes the predicted class for the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b96170a-db75-4d1e-b65e-990ec5550ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
